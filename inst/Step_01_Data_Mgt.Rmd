---
title: \sffamily{\bfseries{\LARGE Criminal History Records Paper Step 1 (Data Management)}}
geometry: "left=.5in,right=.5in,top=.75in,bottom=.75in"
author: "Steven J. Pierce"
output:
 pdf_document:
   latex_engine: xelatex
   number_sections: true
   toc: yes
   toc_depth: 3
   includes:
     in_header: "compact-title.tex"
urlcolor: blue
header-includes:
- \usepackage{fancyhdr}
- \usepackage[yyyymmdd,hhmmss]{datetime}
- \usepackage{lastpage}
- \usepackage{fontspec}
- \defaultfontfeatures{Ligatures=TeX}
- \usepackage[font={small}, margin=1cm, skip=2pt]{caption}
- \usepackage{url}
- \usepackage{floatrow}
- \floatplacement{figure}{!ht}
- \floatplacement{table}{!ht}
- \usepackage{placeins}
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{dcolumn}
- \usepackage{titling}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \pretitle{\begin{center}\LARGE\bfseries}
- \posttitle{\end{center}}
- \pagestyle{fancy}
- \lhead{SSA CHR Paper Step 1 Data Mgt}
- \rhead{\today\ \currenttime}
- \lfoot{\texttt{\small \detokenize{`r sub(".Rmd", ".pdf", knitr:::current_input(dir = FALSE))`}}} 
- \cfoot{ }
- \fancyfoot[R]{\thepage\ of \pageref*{LastPage}}
- \renewcommand{\headrulewidth}{0.4pt}
- \renewcommand{\footrulewidth}{0.4pt}
- \fancypagestyle{plain}{\pagestyle{fancy}}
---

********************************************************************************  
\FloatBarrier

# Purpose
This file imports copies of publicly archived data files (Campbell, 2019) into 
R, then performs data management to prepare a new data file for a descriptive 
paper about the criminal histories of suspected serial sexual perpetrators 
^[In this document, we use the terms perpetrator and offender interchangeably. 
Both terms should be interpreted as referring to individuals suspected of 
committing a crime but we occasionally omit that qualifier for the sake of 
brevity]. The data come from Detroit, MI. 

Part of the analysis will require splitting each offender's criminal history 
into three periods: 

* Before the offender's earliest known sexual assault kit (SAK). 
* During a *testing window* that starts on the date of the offender's earliest 
  known SAK. This window operationalizes the concept of timely forensic testing. 
* After the end of the testing window. 

# Defining Timely Testing
One purpose of forensic testing for SAKs is to prevent future crimes by 
facilitating identification and arrest of suspected offenders. However, forensic
testing takes time to yield results. There are several steps that occur between 
SAK collection and law enforcement personnel being able to act on test results. 

There are examples of testing taking as little as a week for cases deemed to be
emergencies, but for non-emergency cases the testing time in Detroit had 
historically been much longer (typically 6-9 months, but 12-24 months was not 
uncommon) according to local stakeholders. 

Michigan's [2014 Sexual Assault Kit Evidence Submission Act (PA227)](http://www.legislature.mi.gov/(S(hsasgpdffxp4tsy3f3hpbxeo))/documents/mcl/pdf/mcl-Act-227-of-2014.pdf)
provides a working definition of timely testing by stipulating the following
requirements.

* Law enforcement agencies must take possession of an SAK within 14 days of 
  receiving notice from a health care facility that it has been collected. 
* Law enforcement agencies must submit the SAK to a lab for testing within 14 
  days of taking possession of it. 
* Laboratories must complete testing within 90 days after receiving an SAK. 

Adhering to those requirements would mean that law enforcement agencies should
be able to start acting on forensic results no later than 118 days after SAK
collection. Although some practitioners have reservations about the feasibility
of meeting the timing requirements in this law, it is nevertheless the best
working definition of timely testing available because it represents the outcome
of a public policy process in which multiple stakeholders had a voice.

In this study, we adopted an operational definition for the testing window based
on PA227's timing requirements. We defined the testing window as the first 118
days following the earliest SAK date associated with a suspected offender. It is
unrealistic to expect that crimes committed during this period could be
prevented by timely SAK testing because law enforcement personnel cannot act on
information they donâ€™t have yet. Adopting a testing window definition based on 
the maximum duration consistent with the notion of timely testing is useful for
initial descriptive analyses that aim to characterize what crimes might have 
been prevented if timely testing had been done on the SAKs in this sample. 

\FloatBarrier

# Setup
Set global R chunk options (local chunk options will over-ride global options). 
The method for creating a size option that controls font size in code chunks and
their text output is based on an answer to a question posted on   
[stackoverflow.com](https://stackoverflow.com/questions/25646333/code-chunk-font-size-in-rmarkdown-with-knitr-and-latex/46526740#46526740). 

``` {r global_options, cfsize = "footnotesize"}
# Create a custom chunk hook/option for controlling font size in chunk & output.
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$cfsize != "normalsize", paste0("\n \\", options$cfsize,"\n\n", 
                                              x, "\n\n \\normalsize"), x)
  })

# Global chunk options (over-ridden by local chunk options)
knitr::opts_chunk$set(include  = TRUE, echo = TRUE, error = TRUE, 
                      message = TRUE, warning = TRUE, cfsize = "footnotesize")
```

Load R packages that we need to get additional functions. 

``` {r load_packages}
library(here)             # for here()
library(plyr)             # For mapvalues()
library(dplyr)            # for %>%, filter(), group_by(), & summarise()
library(tidyr)            # for arrange(), filter(), group_by(), mutate(),  
                          # spread(), summarise(), %>%, etc. 
library(rmarkdown)        # for render()
library(knitr)            # for kable()
options(kableExtra.latex.load_packages = FALSE)
library(kableExtra)       # for kable_styling(), add_header_above(), column_spec(),
                          # collapse_rows(), and landscape()
library(descr)            # For freq().
options(descr.plot=FALSE) # Make freq() & crosstab() skip plots by default.
library(lubridate)        # For date conversion, eg. ymd(), time_length().
library(sjlabelled)       # For set_label(), get_label()
library(haven)            # for read_spss()
library(lattice)          # For xyplot(), bwplot(), etc. 
library(psych)            # For describe()
library(car)              # For recode()
library(SSACHR)           # for rvlabel()
```

\FloatBarrier

# Import Files
The SPSS files we will need to import, plus documentation about their contents
and relationships between them, are available from an online archive (Campbell,
2019).

\FloatBarrier

## Core Criminal History Records (CHR) Files
Import the SPSS data files for the five core types of records comprising
Michigan criminal history records (CHR): offenders (IDN), incidents (INC),
arrest offenses (ARR), prosecutor charges (CHG), and judicial charges (JUD). 
See Campbell (2019) for details on these files. 

The variables we are updating with *rvlabel()* all have user-missing values with
labels that contain parentheses that are problematic when supplied to the 
*user.missing* argument in *freq()*, so we just remove the parentheses from the 
labels at import.

```{r import_IDN}
read_sav(here::here("./inst/extdata/SSA_IDN_Offenders_2018-09-03.sav"), 
         user_na = TRUE) %>% 
  # Set variable label to match other core CHR files.
  var_labels(OID = "Offender ID (de-identified)") -> 
  IDN

# Make attributes for OID match those in other core CHR files.
attr(IDN$OID, "format.spss") <- "A4"
```

```{r import_INC}
read_sav(here::here("./inst/extdata/SSA_INC_Incidents_Imputed_2018-09-03.sav"), 
         user_na = TRUE) ->
  INC
```

```{r import_ARR}
read_sav(here::here("./inst/extdata/SSA_ARR_Arrests_Imputed_2018-09-03.sav"), 
         user_na = TRUE) %>% 
  # Replace user-missing value labels.
  mutate(ACat12 = rvlabel(ACat12),
         ACat10 = rvlabel(ACat10),
         ACat04 = rvlabel(ACat04)) %>% 
  # Dummy code crime category variables. 
  dcode(x = ., y = factor(.$ACat12), stem = "ACat12") ->
  ARR
```

```{r import_CHG}
read_sav(here::here("./inst/extdata/SSA_CHG_PA_Charges_Imputed_2018-09-03.sav"), 
         user_na = TRUE) %>% 
  # Replace user-missing value labels.
  mutate(CCat12 = rvlabel(CCat12),
         CCat10 = rvlabel(CCat10),
         CCat04 = rvlabel(CCat04)) %>% 
  # Dummy code crime category variables. 
  dcode(x = ., y = factor(.$CCat12), stem = "CCat12") ->
  CHG
```

```{r import_JUD}
read_sav(here::here("./inst/extdata/SSA_JUD_Judicial_Charges_Imputed_2018-09-03.sav"), 
         user_na = TRUE) %>% 
  # Replace user-missing value labels.
  mutate(JCat12 = rvlabel(JCat12),
         JCat10 = rvlabel(JCat10),
         JCat04 = rvlabel(JCat04)) %>% 
  # Dummy code crime category variables. 
  dcode(x = ., y = factor(.$JCat12), stem = "JCat12") ->
  JUD
```

\FloatBarrier

## SAK-Perpetrator Data File
We need this additional data file to identify the earliest SAK associated with
each offender. See Campbell (2019) for details on this file.  

``` {r import_SPD}
# Read SPSS data file.
read_sav(here::here("./inst/extdata/SAK_PERP_2018-04-03.sav"), 
         user_na = TRUE) %>% 
  # Sort by OID and SAK collection date (but NAs are last in sort order).
  arrange(OID, SDate.Yr, SDate.Mt, SDate) %>% 
  # Add a variable showing how many unique SAKs the offender has.
  add_count(OID, name = "OID_NSAK") %>% 
  # Make a OID variable label match the lbel used in CHR data sets. 
  var_labels(OID = "Offender ID (de-identified)",
             OID_NSAK = "No. of unique SAKs associated with this offender") ->
  SPD
```

\FloatBarrier

# Data Management

\FloatBarrier

## Create Conviction Dataset
Convictions are the subset of adjudicated charges that have a specific 
disposition code. For simplicity, we extract them to a new tibble. 
 
```{r create_CON}
# Create a subset of JUD containing only charges where offender was convicted.
JUD %>% 
  # Retain a subset of JUD records based on disposition.
  filter(JDispCat == 1) %>% 
  # Add a variable to CON to simplify aggregation later. 
  mutate(NCON = 1) %>% 
  # Add variable label. 
  var_labels(NCON = "No. of adjudicated charge records w/ convictions") ->
  CON
```

\FloatBarrier

## Merge Number of Convictions onto IDN Dataset

```{r merge_CON_IDN}
# Merge NCON conviction charge count variable into IDN.
CON %>% 
  group_by(OID) %>% 
  summarize_at(.vars = "NCON", .funs = c("sum")) %>% 
  ungroup() %>% 
  left_join(x = IDN, y = ., by = "OID") %>% 
  # Recode NCON variable to replace NA with 0. 
  replace_na(data = ., replace = list(NCON = 0)) %>%  
  # Retain only variables we need, in sensible order. 
  select(all_of(c(names(IDN), "NCON"))) %>% 
  # Add variable label. 
  var_labels(NCON = "No. of adjudicated charge records w/ convictions") -> 
  IDN
```

## Identify Earliest SAK for Each Offender
For the paper, we need to identify the earliest SAK associated with each 
offender who has criminal history data and store those in a new dataset. Along 
the way, we need to do several intermediate tasks. 

According to the help files, *dplyr::arrange* always puts NA values last in 
the sort order. That may affect whether we use that function or another one 
for sorting the data. 

First, we have to trim the SPD data down to just the SAKs associated with 
offenders for whom we have criminal history data (SPDCHR). 

```{r create_SPDCHR}
SPD %>% 
  # Retain only offenders with CHR data. 
  filter(OIDinCHR == "Yes") -> 
  SPDCHR 
```

With the resulting *SPDCHR* data, we need to identify the start of the testing
window for each SAK and store it in a new variable called *WDate*, then
aggregate across SAKs associated with each offender to identify the earliest
*WDate* value. 

\FloatBarrier

### Identify Start of Testing Window for each SAK
The testing window for a SAK should start on the date it was collected. We
already have a variable called *SDate* that records this information. However, 
some SAKs have only partial date information, leaving *SDate* with NA values. A
very small number of SAKs have completely missing data on *SDate* such that not
even the year of collection is known, but most of the cases with missing *SDate*
values have the year of collection recorded in *SDate.Yr* and some also have the
month recorded in *SDate.Mt*.

SAK collection dates (*SDate*) were recorded by hospitals (or other healthcare
providers) who actually collected the SAKs. These dates are very likely to be
accurate because healthcare providers have a strong financial incentive to get
dates of service correct for billing purposes. 

However, when we have missing or partial *SDate* data, we have an additional
source of data that might provide an exact date for the start of the testing
window (*WDate*). In our prior work with these data, we linked some SAKs to
existing CHR incident records that involved criminal sexual conduct (as
evidenced by an associated arrest offense record, prosecutor charge record, or
judicial charge record for a sexual assault). Those links were created to
recognize possible overlap between sexual assaults represented in the CODIS hits
(CHITS) data from the SAK testing and the CHR data files. We did not require
exact date matches in the previous work because we were dealing with data that
originated from different organizations. We allowed up to a 45 day discrepancy
in the dates when making matches.

For SAKs that are not linked to an incident record, *OID_IID* = "" (an empty 
string) and *OID_IDate* = NA. Therefore, the only date information available is
in the SAK collection date variables (*SDate*, *SDate.Yr*, and *SDate.Mt*). If
we have a valid value in *SDate*, then *WDate* = *SDate*. When we only have
partial date information, then *SDate* is missing but *SDate.Yr* and possibly
also *SDate.Mt* have valid values, but we cannot assign a precise date to the
SAK collection and *WDate* ends up with a missing value.

For SAKs that were linked to an incident record, *OID_IID* stores the incident
ID value that links to the CHR incident record in the *INC* data and *OID_IDate*
stores the corresponding incident date. Thus, if *SDate* is missing, we set
*WDate* = *OID_IDate* instead, thereby using *OID_IDate* as supplementary 
information to reduce missing data in *WDate*. 

We also create a *TWindow* date interval variable to record the start and end 
dates for the 118-day testing window for each of these SAKs. 

```{r create_SPDCHRE}
SPDCHR %>% 
  mutate(# Testing Window Start Date.
         WDate = case_when(
           # Default to using SDate if it is not missing. 
           is.na(SDate) == FALSE ~ SDate,
           # If SDate is incomplete or missing, use a valid OID_IDate instead. 
           is.na(SDate) == TRUE & is.na(OID_IDate) == FALSE ~ OID_IDate),
         # Testing Window Start Year.
         WDate.Yr = case_when(
           # Default to year of WDate if it is not missing.
           is.na(WDate) == FALSE ~ year(WDate),
           # Otherwise use SDate.Yr
           is.na(WDate) == TRUE ~ SDate.Yr),
         # Testing Window Start Month.
         WDate.Mt = case_when(
           is.na(WDate) == FALSE ~ month(WDate),
           is.na(WDate) == TRUE ~ SDate.Mt),
         # Testing Window Start Date Status.
         WDate.Status = case_when(
           is.na(WDate) == TRUE & is.na(WDate.Yr) == TRUE ~ "Missing",
           is.na(WDate) == TRUE & is.na(WDate.Mt) == TRUE ~ "Partial.Y",
           is.na(WDate) == TRUE & is.na(WDate.Mt) == FALSE ~ "Partial.YM",
           is.na(WDate) == FALSE ~ "Known"),
         # Testing Window Date Interval.
         TWindow = interval(WDate, WDate + 118)) %>% 
  # Sort records by year, month, and date but ensure that within each layer 
  # records with missing data come first. 
  arrange(OID, -is.na(WDate.Yr), WDate.Yr, -is.na(WDate.Mt), WDate.Mt, WDate) %>% 
  # Group by OID, then select first record for each offender. 
  group_by(OID) %>% 
  filter(row_number() == 1) %>% 
  # Ungroup to ensure simpler, more predictable tibble behavior later. 
  ungroup() %>% 
  # Add variable labels. 
  var_labels(WDate = "Testing Window Start Date",
             WDate.Yr = "Testing Window Start Year",
             WDate.Mt = "Testing Window Start Month",
             WDate.Status = "Testing Window Start Date Status",
             TWindow = "Testing Window Date Interval") ->
  SPDCHRE
```

The code above takes the *SPDCHR* dataset, adds new variables pertaining to 
the start of the testing window, sorts the data into chronological order, then 
drops everything but the earliest SAK for each perpetrator. The result is saved
to the *SPDCHRE* dataset

\FloatBarrier

### Missingness Status for Earliest SAK Testing Window Start Date
Here we pause to assess how many of the offenders with CHR data have missing 
*WDate* values for their earliest SAK. Table \ref{tab:examine_WDate} shows 
a cross-tabulation of the number of SAKs associated with a perpetrator 
(*OID_NSAK*) against the status of the *WDate* variable. 

```{r examine_WDate}
# Table caption.
TCap <- paste("Number of SAKs by WDate Status for Perpetrator's Earliest SAK")
# Footnote text.
FN <- paste("Cells contain counts of perpetrators. Only perpetrators for whom",
            "criminal history records are available were included.",
            "No. SAKs, total number of SAKs associated with perpetrator;",
            "WDate, start date for testing window;",
            "Y, M, and D, respectively refer to the year, month, and day", 
            "components of WDate. Letters replaced by question marks (?)",
            "show which components are unknown.")

# Vector of text values for column labels to be used in the table.
clabels <- c("No. SAKs", "YMD", "YM?", "Y??", "???", "Sum")

addmargins(xtabs(~OID_NSAK + WDate.Status, addNA = TRUE, data = SPDCHRE)) %>% 
  as.data.frame() %>% 
  pivot_wider(names_from = WDate.Status, values_from = Freq) %>% 
  select(OID_NSAK, Known, Partial.YM, Partial.Y, Missing, Sum) %>% 
  kable(., format = "latex", booktabs = TRUE, caption = TCap, 
        col.names = clabels, format.args = list(big.mark = ",")) %>% 
  add_header_above(c("", "Known", "Partial" = 2, "Missing", "")) %>% 
  add_header_above(c("", "WDate Status" = 4, "")) %>% 
  column_spec(1, width = "1.8cm") %>% 
  column_spec(2:6, width = "1.2cm") %>% 
  footnote(general = FN, general_title = "Note: ", footnote_as_chunk = TRUE,
         threeparttable = TRUE)
```

```{r create_SPDCHREW}
SPDCHRE %>% 
  # Retain only the earliest SAKs with known WDate values. 
  filter(WDate.Status == "Known") %>% 
  # Rename variables for clarity. 
  dplyr::rename(ESAKID = SAKID, 
                ESAK_IID = OID_IID) %>% 
  # Add variable labels.
  var_labels(ESAKID = "SAK ID for Offender's Earliest SAK",
             ESAK_IID = "Incident ID for Offender's Earliest SAK",
             TWindow = "Testing Window Date Interval") ->
  SPDCHREW
```

We have complete, known *WDate* values for `r nrow(SPDCHREW)` 
(`r round(100*nrow(SPDCHREW)/nrow(SPDCHRE))`%) of the `r nrow(SPDCHRE)`
perpetrators with CHR data. That leaves `r nrow(SPDCHRE) - nrow(SPDCHREW)`
perpetrators with missing or partial information for *WDate*. For perpetrators 
completely missing values on one or more of their SAKs, it is impossible to tell
which was the earliest SAK. There is no way we can split their criminal 
histories into the three periods for before, during, and after the testing
window. 

We know only the year of earliest SAK collection for most of the perpetrators
with partial *WDate* information. We have not identified a reasonable and
defensible method for imputing precise *WDate* values for these offenders.
Therefore, we have excluded them from the sample analyzed for this paper by
trimming the *SPDCHRE* dataset down to just those offenders who have a known
*WDate* and saving the results as the *SPDCHREW* dataset. This is an 
offender-level dataset. 

\FloatBarrier

## Merge Testing Window Variables Onto IDN Data
Merging the testing window variables onto the *IDN* data is an obvious next
step. Then we subset down to the records that have non-missing *WDate* values
and select only the variables we need to keep before setting a variable label
and saving to a new tibble called *IDNEW*.

```{r create_IDNEW}
SPDCHREW %>% 
  # Retain only variables we need to merge into IDN.
  select(ESAKID, OID, ESAK_IID, WDate, TWindow) %>% 
  # Merge SPDCHREW variables onto INC rows. 
  right_join(x = ., y = IDN, by = "OID") %>% 
  # Retain only IDN records for offenders with non-missing WDate values. 
  filter(is.na(WDate) == FALSE) %>%
  # Retain only variables we need, in sensible order. 
  select(all_of(c(names(IDN), "ESAKID", "ESAK_IID", "WDate", "TWindow"))) %>% 
  # Add a variable label that was otherwise being dropped. 
  var_labels(TWindow = "Testing Window Date Interval") ->
  IDNEW
```

We end up with an *IDNEW* tibble that has `r nrow(IDNEW)` of the original 
`r nrow(IDN)` perpetrators with CHR data. 

## Merge Testing Window Variables Onto Incident Data
The next step is to merge variables from *IDNEW* onto the incident data in *INC*
so that we can classify each incident according to whether it occurred before,
during, or after the earliest testing window for the offender in the new *IWhen*
variable. Along the way we rename some variables and update variable labels for
clarity. Then we select only the variables we need to keep and subset down to
the records that have non-missing *WDate* values and save to a new tibble called
*INCEW*.

```{r create_INCEW}
# Object to hold names of IWhen levels.
IWhenLevels <- c("Before", "During", "After")

# Object to hold names of crucial testing window variables
twvars <- c("ESAKID", "ESAK_IID", "WDate", "TWindow", "IWhen")

# Data management for the merge. 
IDNEW %>% 
  # Retain only variables we need to merge into INC.
  select(ESAKID, OID, ESAK_IID, WDate, TWindow) %>% 
  # Merge IDNEW variables onto INC rows. 
  right_join(x = ., y = INC, by = "OID") %>% 
  # Retain only INC records for offenders with non-missing WDate values. 
  filter(is.na(WDate) == FALSE) %>% 
  # Add more variables. 
  mutate(# Classify incidents as before, during, or after the testing window. 
         IWhen = case_when(
           # If incident matched to earliest SAK, incident was in the window.
           ESAK_IID == IID ~ "During",
           # Otherwise, compare IDate to TWindow to determine if incident was in
           # the window. 
           IDate < int_start(TWindow) ~ "Before",
           IDate %within% TWindow ~ "During",
           IDate > int_end(TWindow) ~ "After")) %>% 
  # Convert IWhen to a factor with levels in sensible order for display.
  mutate(IWhen = factor(IWhen, levels = IWhenLevels, ordered = TRUE)) %>% 
  # Add variable labels.
  var_labels(IWhen = "When was incident relative to testing window?") %>% 
  # Retain only variables we need, in sensible order. 
  select(all_of(c(names(INC), twvars))) %>% 
  # Add another variable label that was otherwise being dropped. 
  var_labels(TWindow = "Testing Window Date Interval") ->
  INCEW
```

Table \ref{tab:examine_INCEW_IWhen} shows the frequency distribution for when 
the incidents occurred relative to the testing window. 

```{r examine_INCEW_IWhen}
# Table caption.
TCap <- paste("Frequency Distribution of When Incident Occurred Relative to",
              "Testing Window")
# Footnote text.
FN <- paste("Only incidents with valid testing window start dates were",
            "included. IWhen, when was incident relative to testing window?")

# Vector of text values for column labels to be used in the table.
clabels <- c("IWhen", "Frequency", "Percent")

xtabs(~IWhen, data = INCEW) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  mutate(Percent = 100*Freq/nrow(INCEW)) %>% 
  kable(., format = "latex", booktabs = TRUE, caption = TCap, digits = 2,
        col.names = clabels, format.args = list(big.mark = ",")) %>% 
  column_spec(1:3, width = "1.5cm") %>% 
  footnote(general = FN, general_title = "Note: ", footnote_as_chunk = TRUE,
         threeparttable = TRUE)
```

We used one special case decision rule when classifying incidents. If an 
incident record had been previously linked to the perpetrator's earliest SAK in
the SPD tibble, then the *IID* variable in the INC record will have a value 
matching the *ESAK_IID* variable merged in from the IDNEW tibble. Such
incidents must by definition be treated as occurring during the testing window
even if the *IDate* lies outside the window. This reflects the notion that we 
are trusting the *SDate* values more than *IDate* values when constructing
*WDate* and *TWindow*. Table \ref{tab:examine_IDate} shows that there are only a
few incidents matched to the perpetrator's earliest SAK where this decision rule
classifies an incident as occurring during the testing window even though
*IDate* actually falls outside that date interval. 

```{r examine_IDate}
# Table caption.
TCap <- paste("Crosstabulation of Whether Incident Date Was Within Testing",
              "Window and Whether Incident Matched to Perpetrator's Earliest",
              "SAK")
# Footnote text.
FN <- paste("Cells contain counts of incidents. Only incidents with valid",
            "testing window start dates were included. ESAK, earliest sexual",
            "assault kit; IDate, incident date; TWindow, testing window.")

# Vector of text values for column labels to be used in the table.
clabels <- c("IDate in TWindow", "FALSE", "TRUE", "Sum")

xtabs(~IDate %within% TWindow + (ESAK_IID == IID), addNA = TRUE, data = INCEW) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  pivot_wider(names_from = ESAK_IID....IID, values_from = Freq) %>% 
  kable(., format = "latex", booktabs = TRUE, caption = TCap, 
        col.names = clabels, format.args = list(big.mark = ",")) %>% 
  add_header_above(c("", "Matched to ESAK" = 2, "")) %>% 
  column_spec(1, width = "3cm") %>% 
  column_spec(2:4, width = "1.5cm") %>% 
  footnote(general = FN, general_title = "Note: ", footnote_as_chunk = TRUE,
         threeparttable = TRUE)
```

Now, we need to get offender-level counts of incidents that occurred before, 
during, and after the testing window respectively called *NINC_Before*, 
*NINC_During*, and *NINC_After*. We can aggregate as follows to get them. We 
will merge these variables into *IDNEW* later. 

```{r create_INCEW_Agg_NINC_IWhen}
INCEW %>% 
  mutate(NINC = 1) %>% 
  group_by(OID, IWhen, .drop = FALSE) %>% 
  # Aggregate by OID and IWhen to get count variables
  summarize(NINC = sum(NINC)) %>% 
  pivot_wider(names_from = IWhen, values_from = NINC, 
              names_glue = "NINC_{IWhen}") %>% 
  var_labels(NINC_Before = "No. of incident records before testing window",
             NINC_During = "No. of incident records during testing window",
             NINC_After  = "No. of incident records after testing window") ->
  INCEW_Agg_NINC_IWhen
```
\FloatBarrier

## Merge Testing Window Variables Onto Arrest Records
The next step is to merge variables from *INCEW* onto the arrest data in *ARR*
so that we can classify each arrest offense record according to whether the
incident associated with it occurred before, during, or after the earliest
testing window for the offender by using *IWhen*. Then we subset down to the
*ARR* records that have non-missing *WDate* values and select only the variables
we need to keep before saving a new tibble called *ARREW*.

```{r create_ARREW}
INCEW %>% 
  # Retain only variables we need to merge into ARR.
  select(IID, ESAKID, ESAK_IID, WDate, TWindow, IWhen) %>% 
  # Merge INCEW variables onto ARR rows. 
  right_join(x = ., y = ARR, by = "IID") %>% 
  # Retain only ARR records for offenders with non-missing WDate values. 
  filter(is.na(WDate) == FALSE) %>% 
  # Retain only variables we need, in sensible order. 
  select(all_of(c(names(ARR), twvars))) %>% 
  # Add a variable label that was otherwise being dropped. 
  var_labels(TWindow = "Testing Window Date Interval") ->
  ARREW 
```

The original *ARR* tibble had `r nrow(ARR)` arrest offense records. Dropping the
records associated with offenders whose earliest testing window could not be
identified leaves `r nrow(ARREW)` arrest offense records in *ARREW*. Table 
\ref{tab:examine_ARREW_IWhen} shows how many arrest offense records were 
associated with incidents that occurred before, during, and after the testing 
window. 

```{r examine_ARREW_IWhen}
# Table caption.
TCap <- paste("Frequency Distribution of When the Incident Associated With An",
              "Arrest Offense Record Occurred Relative to Testing Window")
# Footnote text.
FN <- paste("Only arrest offense records for incidents with valid testing",
            "window start dates were included. IWhen, when was incident", 
            "relative to testing window?")

# Vector of text values for column labels to be used in the table.
clabels <- c("IWhen", "Frequency", "Percent")

xtabs(~IWhen, data = ARREW) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  mutate(Percent = 100*Freq/nrow(ARREW)) %>% 
  kable(., format = "latex", booktabs = TRUE, caption = TCap, digits = 2,
        col.names = clabels, format.args = list(big.mark = ",")) %>% 
  column_spec(1:3, width = "1.5cm") %>% 
  footnote(general = FN, general_title = "Note: ", footnote_as_chunk = TRUE,
         threeparttable = TRUE)
```

Now, we need to get offender-level counts of arrest offense records associated 
with incidents that occurred before, during, and after the testing window 
respectively called *NARR_Before*, *NARR_During*, and *NARR_After*. We can 
aggregate as follows to get them. We will merge these variables into *IDNEW* 
later. 

```{r create_ARREW_Agg_NARR_IWhen}
ARREW %>% 
  mutate(NARR = 1) %>% 
  group_by(OID, IWhen, .drop = FALSE) %>% 
  # Aggregate by OID and IWhen to get count variables
  summarize(NARR = sum(NARR)) %>% 
  pivot_wider(names_from = IWhen, values_from = NARR, 
              names_glue = "NARR_{IWhen}") %>% 
  var_labels(NARR_Before = "No. of arrest offense records before testing window",
             NARR_During = "No. of arrest offense records during testing window",
             NARR_After  = "No. of arrest offense records after testing window") ->
  ARREW_Agg_NARR_IWhen
```

\FloatBarrier

## Merge Testing Window Variables Onto Prosecutor Charge Records
The next step is to merge variables from *INCEW* onto the charge data in *CHG*
so that we can classify each prosecutor charge record according to whether the
incident associated with it occurred before, during, or after the earliest
testing window for the offender by using *IWhen*. Then we subset down to the
*CHG* records that have non-missing *WDate* values and select only the variables
we need to keep before saving a new tibble called *CHGEW*.

```{r create_CHGEW}
INCEW %>% 
  # Retain only variables we need to merge into ARR.
  select(IID, ESAKID, ESAK_IID, WDate, TWindow, IWhen) %>% 
  # Merge INCEW variables onto CHG rows. 
  right_join(x = ., y = CHG, by = "IID") %>% 
  # Retain only CHG records for offenders with non-missing WDate values. 
  filter(is.na(WDate) == FALSE) %>% 
  # Retain only variables we need, in sensible order. 
  select(all_of(c(names(CHG), twvars))) %>% 
  # Add a variable label that was otherwise being dropped. 
  var_labels(TWindow = "Testing Window Date Interval") ->
  CHGEW 
```

The original *CHG* tibble had `r nrow(CHG)` prosecutor charge records. Dropping
the records associated with offenders whose earliest testing window could not be
identified leaves `r nrow(CHGEW)` prosecutor charge  records in *CHGEW*. Table
\ref{tab:examine_CHGEW_IWhen} shows how many prosecutor charge records were
associated with incidents that occurred before, during, and after the testing
window.

```{r examine_CHGEW_IWhen}
# Table caption.
TCap <- paste("Frequency Distribution of When the Incident Associated With A",
              "Prosecutor Charge Record Occurred Relative to Testing Window")
# Footnote text.
FN <- paste("Only prosecutor charge records for incidents with valid testing",
            "window start dates were included. IWhen, when was incident", 
            "relative to testing window?")

# Vector of text values for column labels to be used in the table.
clabels <- c("IWhen", "Frequency", "Percent")

xtabs(~IWhen, data = CHGEW) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  mutate(Percent = 100*Freq/nrow(CHGEW)) %>% 
  kable(., format = "latex", booktabs = TRUE, caption = TCap, digits = 2,
        col.names = clabels, format.args = list(big.mark = ",")) %>% 
  column_spec(1:3, width = "1.5cm") %>% 
  footnote(general = FN, general_title = "Note: ", footnote_as_chunk = TRUE,
         threeparttable = TRUE)
```

Now, we need to get offender-level counts of prosecutor charge records
associated with incidents that occurred before, during, and after the testing
window  respectively called *NCHG_Before*, *NCHG_During*, and *NCHG_After*. We
can aggregate as follows to get them. We will merge these variables into *IDNEW*
later.

```{r create_CHGEW_Agg_NCHG_IWhen}
CHGEW %>% 
  mutate(NCHG = 1) %>% 
  group_by(OID, IWhen, .drop = FALSE) %>% 
  # Aggregate by OID and IWhen to get count variables
  summarize(NCHG = sum(NCHG)) %>% 
  pivot_wider(names_from = IWhen, values_from = NCHG, 
              names_glue = "NCHG_{IWhen}") %>% 
  var_labels(NCHG_Before = "No. of prosecutor charge records before testing window",
             NCHG_During = "No. of prosecutor charge records during testing window",
             NCHG_After  = "No. of prosecutor charge records after testing window") ->
  CHGEW_Agg_NCHG_IWhen
```

\FloatBarrier

## Merge Testing Window Variables Onto Judicial Charge Records
The next step is to merge variables from *INCEW* onto the charge data in *JUD*
so that we can classify each judicial charge record according to whether the
incident associated with it occurred before, during, or after the earliest
testing window for the offender by using *IWhen*. Then we subset down to the
*JUD* records that have non-missing *WDate* values and select only the variables
we need to keep before saving a new tibble called *JUDEW*.

```{r create_JUDEW}
INCEW %>% 
  # Retain only variables we need to merge into ARR.
  select(IID, ESAKID, ESAK_IID, WDate, TWindow, IWhen) %>% 
  # Merge INCEW variables onto JUD rows. 
  right_join(x = ., y = JUD, by = "IID") %>% 
  # Retain only CHG records for offenders with non-missing WDate values. 
  filter(is.na(WDate) == FALSE) %>% 
  # Retain only variables we need, in sensible order. 
  select(all_of(c(names(JUD), twvars))) %>% 
  # Add a variable label that was otherwise being dropped. 
  var_labels(TWindow = "Testing Window Date Interval") ->
  JUDEW 
```

The original *JUD* tibble had `r nrow(JUD)` judicial charge records. Dropping
the records associated with offenders whose earliest testing window could not be
identified leaves `r nrow(JUDEW)` judicial charge records in *JUDEW*. Table
\ref{tab:examine_JUDEW_IWhen} shows how many judicial charge records were
associated with incidents that occurred before, during, and after the testing
window.

```{r examine_JUDEW_IWhen}
# Table caption.
TCap <- paste("Frequency Distribution of When the Incident Associated With A",
              "Judicial Charge Record Occurred Relative to Testing Window")
# Footnote text.
FN <- paste("Only judicial charge records for incidents with valid testing",
            "window start dates were included. IWhen, when was incident", 
            "relative to testing window?")

# Vector of text values for column labels to be used in the table.
clabels <- c("IWhen", "Frequency", "Percent")

xtabs(~IWhen, data = JUDEW) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  mutate(Percent = 100*Freq/nrow(JUDEW)) %>% 
  kable(., format = "latex", booktabs = TRUE, caption = TCap, digits = 2,
        col.names = clabels, format.args = list(big.mark = ",")) %>% 
  column_spec(1:3, width = "1.5cm") %>% 
  footnote(general = FN, general_title = "Note: ", footnote_as_chunk = TRUE,
         threeparttable = TRUE)
```

Now, we need to get offender-level counts of judicial charge records associated
with incidents that occurred before, during, and after the testing window
respectively called *NJUD_Before*, *NJUD_During*, and *NJUD_After*. We can
aggregate as follows to get them. We will merge these variables into *IDNEW*
later.

```{r create_JUDEW_Agg_NJUD_IWhen}
JUDEW %>% 
  mutate(NJUD = 1) %>% 
  group_by(OID, IWhen, .drop = FALSE) %>% 
  # Aggregate by OID and IWhen to get count variables
  summarize(NJUD = sum(NJUD)) %>% 
  pivot_wider(names_from = IWhen, values_from = NJUD, 
              names_glue = "NJUD_{IWhen}") %>% 
  var_labels(NJUD_Before = "No. of adjudicated charge records before testing window",
             NJUD_During = "No. of adjudicated charge records during testing window",
             NJUD_After  = "No. of adjudicated charge records after testing window") ->
  JUDEW_Agg_NJUD_IWhen
```

\FloatBarrier

## Merge Testing Window Variables Onto Conviction Records
The next step is to merge variables from *INCEW* onto the charge data in *CON*
so that we can classify each conviction record according to whether the
incident associated with it occurred before, during, or after the earliest
testing window for the offender by using *IWhen*. Then we subset down to the
*CON* records that have non-missing *WDate* values and select only the variables
we need to keep before saving a new tibble called *CONEW*.

```{r create_CONEW}
INCEW %>% 
  # Retain only variables we need to merge into ARR.
  select(IID, ESAKID, ESAK_IID, WDate, TWindow, IWhen) %>% 
  # Merge INCEW variables onto JUD rows. 
  right_join(x = ., y = CON, by = "IID") %>% 
  # Retain only CHG records for offenders with non-missing WDate values. 
  filter(is.na(WDate) == FALSE) %>% 
  # Retain only variables we need, in sensible order. 
  select(all_of(c(names(JUD), twvars))) %>% 
  # Add a variable label that was otherwise being dropped. 
  var_labels(TWindow = "Testing Window Date Interval") ->
  CONEW 
```

The original *CON* tibble had `r nrow(CON)` conviction records. Dropping
the records associated with offenders whose earliest testing window could not be
identified leaves `r nrow(CONEW)` judicial charge records in *CONEW*. Table
\ref{tab:examine_CONEW_IWhen} shows how many conviction records were
associated with incidents that occurred before, during, and after the testing
window.

```{r examine_CONEW_IWhen}
# Table caption.
TCap <- paste("Frequency Distribution of When the Incident Associated With A",
              "Conviction Record Occurred Relative to Testing Window")
# Footnote text.
FN <- paste("Only conviction records for incidents with valid testing",
            "window start dates were included. IWhen, when was incident", 
            "relative to testing window?")

# Vector of text values for column labels to be used in the table.
clabels <- c("IWhen", "Frequency", "Percent")

xtabs(~IWhen, data = CONEW) %>% 
  addmargins() %>% 
  as.data.frame() %>% 
  mutate(Percent = 100*Freq/nrow(CONEW)) %>% 
  kable(., format = "latex", booktabs = TRUE, caption = TCap, digits = 2,
        col.names = clabels, format.args = list(big.mark = ",")) %>% 
  column_spec(1:3, width = "1.5cm") %>% 
  footnote(general = FN, general_title = "Note: ", footnote_as_chunk = TRUE,
         threeparttable = TRUE)
```

Now, we need to get offender-level counts of conviction records associated
with incidents that occurred before, during, and after the testing window
respectively called *NCON_Before*, *NCON_During*, and *NCON_After*. We can
aggregate as follows to get them. We will merge these variables into *IDNEW*
later.

```{r create_CONEW_Agg_NCON_IWhen}
CONEW %>% 
  mutate(NCON = 1) %>% 
  group_by(OID, IWhen, .drop = FALSE) %>% 
  # Aggregate by OID and IWhen to get count variables
  summarize(NCON = sum(NCON)) %>% 
  pivot_wider(names_from = IWhen, values_from = NCON, 
              names_glue = "NCON_{IWhen}") %>% 
  var_labels(NCON_Before = "No. of conviction records before testing window",
             NCON_During = "No. of conviction records during testing window",
             NCON_After  = "No. of conviction records after testing window") ->
  CONEW_Agg_NCON_IWhen
```
\FloatBarrier

## Aggregating Crime Category Variables
Here we aggregate the dummy coded crime category variables data first to the
incident level to flag presence of each crime category on the incident, then 
to offender level incident counts for each crime category. 

```{r create_acjvars}
# Create objects with vectors of variable names
avars      <- paste("ACat12", c(1:12, 999), sep = "_")
avarsb     <- paste0(avars, "_Before")
avarsd     <- paste0(avars, "_During")
avarsa     <- paste0(avars, "_After")
avarsbda   <- c(avarsb, avarsd, avarsa)
cvars      <- paste("CCat12", c(1:12, 999), sep = "_")
cvarsb     <- paste0(cvars, "_Before")
cvarsd     <- paste0(cvars, "_During")
cvarsa     <- paste0(cvars, "_After")
cvarsbda   <- c(cvarsb, cvarsd, cvarsa)
jvars      <- paste("JCat12", c(1:12, 999), sep = "_")
jvarsb     <- paste0(jvars, "_Before")
jvarsd     <- paste0(jvars, "_During")
jvarsa     <- paste0(jvars, "_After")
jvarsbda   <- c(jvarsb, jvarsd, jvarsa)
acjvars    <- c(avars, cvars, jvars)
acjvarsb   <- c(avarsb, cvarsb, jvarsb)
acjvarsd   <- c(avarsd, cvarsd, jvarsd)
acjvarsa   <- c(avarsa, cvarsa, jvarsa)
acjvarsbda <- c(avarsbda, cvarsbda, jvarsbda)
```

### Incidents With Arrests

```{r create_ARREWAgg2}
# Aggregate ACat12 dummy codes to offender level incident counts.
ARREW %>% 
  group_by(OID, IID) %>% 
  # Aggregate dummy codes by OID + IID into binary variables
  summarize(across(.cols = all_of(avars), .fns = max)) %>% 
  group_by(OID) %>% 
  # Aggregate dummy codes by OID into incident count variables
  summarize(across(.cols = all_of(avars), .fns = sum)) ->
  ARREWAgg2
```

```{r create_ARREWAgg3}
# Aggregate ACat12 dummy codes to offender level incident counts.
ARREW %>% 
  group_by(OID, IID, IWhen, .drop = FALSE) %>% 
  # Aggregate dummy codes by OID + IID into binary variables
  summarize(across(.cols = all_of(avars), .fns = robustmax)) %>% 
  pivot_wider(names_from = IWhen, values_from = all_of(avars), 
              values_fill = 0) %>%
  group_by(OID) %>% 
  # Aggregate dummy codes by OID into incident count variables
  summarize(across(.cols = all_of(avarsbda), .fns = sum, na.rm = TRUE)) ->
  ARREWAgg3
```

### Incidents With Charges

```{r create_CHGEWAgg2}         
# Aggregate CCat12 dummy codes to offender level incident counts.
CHGEW %>% 
  group_by(OID, IID) %>% 
  # Aggregate dummy codes by OID + IID into binary variables
  summarize(across(.cols = all_of(cvars), .fns = max)) %>% 
  group_by(OID) %>% 
  # Aggregate dummy codes by OID into incident count variables
  summarize(across(.cols = all_of(cvars), .fns = sum)) ->
  CHGEWAgg2
```

```{r create_CHGEWAgg3}
# Aggregate CCat12 dummy codes to offender level incident counts.
CHGEW %>% 
  group_by(OID, IID, IWhen, .drop = FALSE) %>% 
  # Aggregate dummy codes by OID + IID into binary variables
  summarize(across(.cols = all_of(cvars), .fns = robustmax)) %>% 
  pivot_wider(names_from = IWhen, values_from = all_of(cvars), 
              values_fill = 0) %>%
  group_by(OID) %>% 
  # Aggregate dummy codes by OID into incident count variables
  summarize(across(.cols = all_of(cvarsbda), .fns = sum, na.rm = TRUE)) ->
  CHGEWAgg3
```


### Incidents With Convictions

```{r create_CONEWAgg2}
# Aggregate JCat12 dummy codes to offender level incident counts.
CONEW %>% 
  group_by(OID, IID) %>% 
  # Aggregate dummy codes by OID + IID into binary variables
  summarize(across(.cols = all_of(jvars), .fns = max)) %>% 
  group_by(OID) %>% 
  # Aggregate dummy codes by OID into incident count variables
  summarize(across(.cols = all_of(jvars), .fns = sum)) ->
  CONEWAgg2
```

```{r create_CONEWAgg3}
# Aggregate JCat12 dummy codes to offender level incident counts.
CONEW %>% 
  group_by(OID, IID, IWhen, .drop = FALSE) %>% 
  # Aggregate dummy codes by OID + IID into binary variables
  summarize(across(.cols = all_of(jvars), .fns = robustmax)) %>% 
  pivot_wider(names_from = IWhen, values_from = all_of(jvars), 
              values_fill = 0) %>%
  group_by(OID) %>% 
  # Aggregate dummy codes by OID into incident count variables
  summarize(across(.cols = all_of(jvarsbda), .fns = sum, na.rm = TRUE)) ->
  CONEWAgg3
```

# Incidents with Any CHR Criminal Sexual Conduct Records
The *INCEW* data frame contains a binary variable called *CSC_ANY* that marks
which incidents are associated with any other criminal history records for
criminal sexual conduct (e.g., arrest offense records, prosecutor charge
records, or adjudicated charge records, which may or may not be convictions). 
We are aggregating that variable and also creating a similar binary variable
called *CSCHistory* that marks incidents which are associated with 1 or more
criminal history records for criminal sexual conduct that indicate there was an
arrest, prosecutor charge, or a conviction. This *CSCHistory* variable is a more
stringent definition than *CSC_ANY* because it codes incidents that had 
adjudicated charges for CSC that were not convictions (and had no CSC arrests or 
prosecutor charges) as 0, whereas *CSC_ANY* would code them as 1. 

Here, we aggregate in order to create *NCSC_ANY* and *NCSCHistory*, which will
respectively be offender-level counts of incidents for which *CSC_ANY* = 1 and
*CSCHistory* = 1. We will merge these variable into *IDNEW* later.

```{r create_INCEWAgg2} 
INCEW %>% 
  mutate(CSCHistory = if_else(CSC_ARR + CSC_CHG + CSC_CON >= 1, 
                              true = 1, false = 0)) %>% 
  group_by(OID, .drop = FALSE) %>% 
  # Aggregate by OID to get count variable
  summarize(NCSC_ANY = sum(CSC_ANY),
            NCSCHistory = sum(CSCHistory)) %>% 
  var_labels(NCSC_ANY = "No. of incidents with >= 1 CSC criminal history records of any type",
             NCSCHistory = "No. of incidents with >= 1 CSC arrest, charge, or conviction in CHR data") ->
  INCEWAgg2
```

Now, we need to get offender-level breakdowns of those CSC incident counts for 
incidents that occurred before, during, and after the testing window. We can 
aggregate as follows to get them. We will merge these variables into *IDNEW* 
later. 

```{r create_INCEWAgg3}
INCEW %>% 
  mutate(CSCHistory = if_else(CSC_ARR + CSC_CHG + CSC_CON >= 1, 
                              true = 1, false = 0)) %>%
  group_by(OID, IWhen, .drop = FALSE) %>% 
  # Aggregate by OID and IWhen to get count variables
  summarize(NCSC_ANY = sum(CSC_ANY),
            NCSCHistory = sum(CSCHistory)) %>% 
  pivot_wider(names_from = IWhen, values_from = c(NCSC_ANY, NCSCHistory)) %>% 
  var_labels(NCSC_ANY_Before = "No. of incidents with >= 1 CSC criminal history records of any type before testing window",
             NCSC_ANY_During = "No. of incidents with >= 1 CSC criminal history records of any type during testing window",
             NCSC_ANY_After  = "No. of incidents with >= 1 CSC criminal history records of any type after testing window",
             NCSCHistory_Before = "No. of incidents with >= 1 CSC arrest, charge, or conviction in CHR data before testing window",
             NCSCHistory_During = "No. of incidents with >= 1 CSC arrest, charge, or conviction in CHR data during testing window",
             NCSCHistory_After = "No. of incidents with >= 1 CSC arrest, charge, or conviction in CHR data after testing window") ->
  INCEWAgg3
```

# Merge Aggregated Variables onto IDNEW
First, we merge additional record count variables into *IDNEW* via *left_join()*
because it preserves variable attributes better than *merge()* and is more
compatible with the tidyverse style and the pipe operator %>%. Then, we merge in 
crime category incident counts variables as well. After merging, we replace the
missing values in the new variables with zeroes, then compute some additional
variables as well.

```{r update_IDNEW}
rcvars <- paste(rep(c("NINC", "NARR", "NCHG", "NJUD", "NCON"), each = 3), 
                rep(IWhenLevels, times = 5), sep = "_")
ncscanyvars <- c("NCSC_ANY", paste("NCSC_ANY", IWhenLevels, sep = "_"))

IDNEW %>% 
  # Merge in incident record count variables
  left_join(x = ., y = INCEW_Agg_NINC_IWhen, by = "OID") %>% 
  # Merge in incident count variables for CSC_ANY and CSCHistory.
  left_join(x = ., y = INCEWAgg2, by = "OID") %>% 
  # Merge in arrest record count variables
  left_join(x = ., y = ARREW_Agg_NARR_IWhen, by = "OID") %>% 
  # Merge in charge record count variables
  left_join(x = ., y = CHGEW_Agg_NCHG_IWhen, by = "OID") %>% 
  # Merge in judicial charge record count variables
  left_join(x = ., y = JUDEW_Agg_NJUD_IWhen, by = "OID") %>% 
  # Merge in conviction record count variables
  left_join(x = ., y = CONEW_Agg_NCON_IWhen, by = "OID") %>% 
  # Merge in ACat12 incident count variables 
  left_join(x = ., y = ARREWAgg2, by = "OID") %>% 
  # Merge in CCat12 incident count variables 
  left_join(x = ., y = CHGEWAgg2, by = "OID") %>% 
  # Merge in JCat12 incident count variables (for convictions only)
  left_join(x = ., y = CONEWAgg2, by = "OID") %>% 
  # Merge in incident count variables for CSC_ANY and CSCHistory split by IWhen
  left_join(x = ., y = INCEWAgg3, by = "OID") %>%
  # Merge in ACat12 incident count variables split by IWhen 
  left_join(x = ., y = ARREWAgg3, by = "OID") %>% 
  # Merge in CCat12 incident count variables split by IWhen 
  left_join(x = ., y = CHGEWAgg3, by = "OID") %>% 
  # Merge in JCat12 incident count variables (for convictions only) split by IWhen 
  left_join(x = ., y = CONEWAgg3, by = "OID") %>% 
  # Replace all NA values in the new variables with 0. 
  mutate(across(.cols = all_of(c(acjvars, acjvarsbda, rcvars, ncscanyvars)), 
                .fns = replace_na, replace = 0)) %>% 
  # Count the number of crime categories associated w/ each offender.
  rowwise() %>% 
  mutate(ACat12_Count = sum(c_across(all_of(avars[1:12])) > 0),
         ACat12_Count_Before = sum(c_across(all_of(avarsb[1:12])) > 0),
         ACat12_Count_During = sum(c_across(all_of(avarsd[1:12])) > 0),
         ACat12_Count_After = sum(c_across(all_of(avarsa[1:12])) > 0),
         CCat12_Count = sum(c_across(all_of(cvars[1:12])) > 0),
         CCat12_Count_Before = sum(c_across(all_of(cvarsb[1:12])) > 0),
         CCat12_Count_During = sum(c_across(all_of(cvarsd[1:12])) > 0),
         CCat12_Count_After = sum(c_across(all_of(cvarsa[1:12])) > 0),
         JCat12_Count = sum(c_across(all_of(jvars[1:12])) > 0),
         JCat12_Count_Before = sum(c_across(all_of(jvarsb[1:12])) > 0),
         JCat12_Count_During = sum(c_across(all_of(jvarsd[1:12])) > 0),
         JCat12_Count_After = sum(c_across(all_of(jvarsa[1:12])) > 0)) %>% 
  var_labels(ACat12_Count = "Arrested crime category count (overall)",
             ACat12_Count_Before = "Arrested crime category count (incidents before testing window)",
             ACat12_Count_During = "Arrested crime category count (incidents during testing window)",
             ACat12_Count_After = "Arrested crime category count (incidents after testing window)",
             CCat12_Count = "Charged crime category count (overall)",
             CCat12_Count_Before = "Charged crime category count (incidents before testing window)",
             CCat12_Count_During = "Charged crime category count (incidents during testing window)",
             CCat12_Count_After = "Charged crime category count (incidents after testing window)",
             JCat12_Count = "Convicted crime category count (overall)",
             JCat12_Count_Before = "Convicted crime category count (incidents before testing window)",
             JCat12_Count_During = "Convicted crime category count (incidents during testing window)",
             JCat12_Count_After = "Convicted crime category count (incidents after testing window)") -> 
  IDNEW
```

# Check Assumptions
We actually have few redundant incident count variables in *IDNEW* now. The
variables OCSC1, OCSC2, and OCSC3 were created and stored in the SPSS file
during the original grant work. The variables ACat12_5, CCat12_5, and JCat12_5
respectively contain exactly the same data, but were created above in the 
**Aggregating Crime Category Variables** section. They should agree with one
another and we can check that as follows to prove that the aggregation logic was
implemented the same way.

```{r check_assumptions}
# Verify that OCSC1 = ACat12_5, OCSC2 = CCat12_5, & OCSC3 = JCat12_5.
all(IDNEW$OCSC1 == IDNEW$ACat12_5) # Arrest incident counts
all(IDNEW$OCSC2 == IDNEW$CCat12_5) # Charge incident counts
all(IDNEW$OCSC3 == IDNEW$JCat12_5) # Conviction incident counts
```

The variables *CSC_ANY* and *CSCHistory* have very similar definitions. It is 
possible that they have identical values for all incidents and so the aggregated
variables *NCSC_ANY* and *NCSCHistory* could be identical. Let's demonstrate 
that this is false. 

```{r check_assumption2}
# Are NCSC_ANY and NCSCHistory always the same? 
addmargins(table(INCEWAgg2$NCSC_ANY == INCEWAgg2$NCSCHistory))
```

So, they are very similar, but not quite identical. We will retain both 
variables, but may only analyze one of them. It is important to note that the 
relation between them is *NCSC_ANY* $\geq$ *NCSCHistory* because the latter 
variable has a narrower definition.

# Criminal History Record (CHR) Count Overview
Below is a summary of the record counts for different types of CHR records, 
along with the numbers of unique incidents and unique offenders represented in
those records. It also shows the range of event dates associated with each 
record type (i.e., birth, incident, arrest, charge, and adjudication dates). 

```{r chr_overview, warning = FALSE}
# Table caption.
TCap <- paste("Criminal History Record Counts and Date Ranges Before Versus",
              "After Case Selection Based on Testing Window Data")

# Summarize record counts before & after case selection for this study.
bind_rows(dfsummary(IDN, label = "Offenders...Before", dvar = IDN$DOB),
          dfsummary(IDNEW, label = "Offenders...After", dvar = IDNEW$DOB),
          dfsummary(INC, label = "Incidents...Before", dvar = INC$IDate), 
          dfsummary(INCEW, label = "Incidents...After", dvar = INCEW$IDate), 
          dfsummary(ARR, label = "Arrest offenses...Before", dvar = ARR$ADate),
          dfsummary(ARREW, label = "Arrest offenses...After", 
                    dvar = ARREW$ADate),
          dfsummary(CHG, label = "Prosecutor charges...Before", 
                    dvar = CHG$CDate),
          dfsummary(CHGEW, label = "Prosecutor charges...After", 
                    dvar = CHGEW$CDate),
          dfsummary(JUD, label = "Adjudicated charges (all dispositions)...Before", 
                    dvar = JUD$JDate),
          dfsummary(JUDEW, label = "Adjudicated charges (all dispositions)...After", 
                    dvar = JUDEW$JDate),
          dfsummary(CON, label = "Adjudicated charges (convictions)...Before", 
                    dvar = CON$JDate),
          dfsummary(CONEW, label = "Adjudicated charges (convictions)...After", 
                    dvar = CONEW$JDate)) ->
  CHR.RC
kable(CHR.RC, format = "latex", booktabs = TRUE, caption = TCap, 
      format.args = list(big.mark = ','))
```

\FloatBarrier

# Save Data to a File

```{r save_data}
save(IDNEW, INCEW, ARREW, CHGEW, JUDEW, CONEW, 
     file = here::here("./data/CHR_Data.RData"))
```

# Wrap Up

\FloatBarrier

## Project Information
These materials are scholarly products based on research funded by the following 
grant. 

Campbell, R., Pierce, S. J., & Sharma, D. (01/01/2015â€“12/31/2018). Serial sexual
assaults: A longitudinal examination of offending patterns using DNA evidence.
[NIJ Award # 2014-NE-BX-0006, Awarded, $699,533]. Sponsor: National Institute of
Justice. Location: Michigan State University, East Lansing, MI.

\FloatBarrier

## References
Campbell, R. (2019). *Serial sexual assaults: A longitudinal examination of
offending patterns using DNA evidence, Detroit, Michigan, 2009* [Data files,
codebooks, computer programs, and statistical output]. ICPSR37134-v1. Ann Arbor,
MI: Inter-university Consortium for Political and Social Research [distributor],
2019-02-28. Retrieved from: https://doi.org/10.3886/ICPSR37134.v1

\FloatBarrier

## Software Information
We use R Markdown to enhance reproducibility. Knitting the source R Markdown 
script *`r knitr:::current_input()`* generates this PDF file containing 
explanatory text, R code, plus R output (text and graphics).

- We used [RStudio](www.rstudio.org) `r rstudioapi::versionInfo()$version` to 
  work with R and R markdown files. The software chain looks like this:
  **Rmd file > RStudio > R > rmarkdown > knitr > pandoc > TinyTeX or MiKTeX > PDF file**.
- We recommend using [TinyTeX](https://yihui.org/tinytex/) to compile LaTeX files 
  into PDF files. However, it should be viable to use 
  [MiKTeX version 2.9](https://miktex.org) instead. 
- We used [pandoc](https://pandoc.org) `r pandoc_version()` for this 
  document. 

This document was generated using the following computational environment and 
dependencies: 

``` {r show_citations}
# If is_tineytex = TRUE, then we used TinyTeX, otherwise we used MikTeX. 
tinytex:::is_tinytex()

# Get R and R package version numbers in use.
devtools::session_info()
```

The current Git commit details and status are:

```{r git_details, eval=TRUE}
# Store whether git2r is installed and we are in a git repository.
GitCheck <- "git2r" %in% installed.packages() & git2r::in_repository(path = ".")
cat(paste("GitCheck =", GitCheck, "\n"))

# What commit is this file at? 
if (GitCheck) git2r::repository(here::here())

# What is the repository status? 
if (GitCheck) git2r::status()
```
